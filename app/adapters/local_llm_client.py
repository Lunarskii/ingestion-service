from app.interfaces import LLMClient


class LocalLLMClient(LLMClient):
    """
    Заглушка LLM для локальных тестов и разработки.
    Возвращает синтетические ответы вместо реальной обработки.
    """

    def generate(self, prompt: str) -> str:
        """
        Функция-заглушка для генерации ответа LLM.

        Принимает на вход текстовый `prompt` и возвращает строку,
        эмулирующую ответ большой языковой модели.

        :param prompt: Исходный запрос для LLM.

        :return: Синтетический ответ, включающий оригинальный ``prompt``.
        """

        return f"Имитация ответа LLM.\n\n[Получен следующий промпт для обработки]:\n{prompt}"
